{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install bm25s\n",
    "# %pip install spacy\n",
    "# %pip install -U 'spacy[cuda12x]'\n",
    "# %pip install rouge_score\n",
    "# %pip install pysbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    }
   ],
   "source": [
    "import functions as fct\n",
    "import bm25s\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Définition des chemins vers les fichiers JSON d'entraînement et de développement\n",
    "# train_path = 'SCOTUS/train.json'\n",
    "# dev_path = 'SCOTUS/dev.json'\n",
    "\n",
    "# # Ouverture du fichier d'entraînement\n",
    "# train = fct.open_file(train_path, \"json\")\n",
    "\n",
    "# # Récupération du document source du premier élément de l'ensemble d'entraînement\n",
    "# # document = train[0][\"raw_source\"]\n",
    "# document = train\n",
    "\n",
    "# # Récupération des éléments de la cible (faits, question, conclusion)\n",
    "# paragraph_target = (\n",
    "#     train[0]['raw_target']['facts_of_the_case'] +\n",
    "#     train[0]['raw_target']['question'] +\n",
    "#     train[0]['raw_target']['conclusion']\n",
    "# )\n",
    "\n",
    "# train_path = 'data_txt_save/train_0.txt'\n",
    "# train = fct.open_file(train_path, \"txt\")\n",
    "\n",
    "# document = train\n",
    "\n",
    "\n",
    "# # Segmentation des phrases du document source\n",
    "# sentences = fct.sent_segmentation(document, method='custom_spacy')\n",
    "\n",
    "# # Résumé des phrases en utilisant le modèle BERT\n",
    "# summary = fct.bb25LegalSum(sentences, \"bert-base-uncased\", 5)\n",
    "\n",
    "# # Évaluation de la qualité du résumé à l'aide de la métrique ROUGE\n",
    "# bb25_rouge = fct.rouge_evaluations(\" \".join(summary), paragraph_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb25_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des chemins vers les fichiers JSON d'entraînement et de développement\n",
    "train_path_json = 'SCOTUS/train.json'\n",
    "dev_path_json = 'SCOTUS/dev.json'\n",
    "\n",
    "# Ouverture du fichier d'entraînement JSON\n",
    "train_json = fct.open_file(train_path_json, \"json\")\n",
    "\n",
    "# Récupération du document source et des éléments de la cible (faits, question, conclusion)\n",
    "document_json = train_json[0][\"raw_source\"]\n",
    "paragraph_target_json = (\n",
    "    train_json[0]['raw_target']['facts_of_the_case'] +\n",
    "    train_json[0]['raw_target']['question'] +\n",
    "    train_json[0]['raw_target']['conclusion']\n",
    ")\n",
    "\n",
    "# Définir le chemin du fichier texte à traiter\n",
    "train_path_txt = 'data_txt_save/train_0.txt'\n",
    "clean_path_txt = 'clean_data_txt_save/train_0.txt'\n",
    "\n",
    "# Ouverture du fichier d'entraînement TXT\n",
    "document_txt = fct.open_file(train_path_txt, \"txt\")\n",
    "clean_document_txt = fct.open_file(clean_path_txt, \"txt\")\n",
    "\n",
    "# Liste des méthodes de segmentation et des modèles à tester\n",
    "methods = ['nltk', 'spacy', 'pySBD', 'custom_spacy']  # Méthodes de segmentation à tester\n",
    "model = \"bert-base-uncased\"  # Modèle de résumé à utiliser\n",
    "\n",
    "def save_txt(text, folder_name, file_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(text)\n",
    "\n",
    "# Fonction pour évaluer les modèles\n",
    "def evaluate_models(document, paragraph_target, file_type):\n",
    "    results = []\n",
    "    for method in methods:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Segmentation des phrases du document source\n",
    "        sentences = fct.sent_segmentation(document, method=method)\n",
    "        \n",
    "        # Résumé des phrases\n",
    "        summary = fct.bb25LegalSum(sentences, model, 5)\n",
    "        \n",
    "        # Évaluation de la qualité du résumé à l'aide de la métrique ROUGE\n",
    "        bb25_rouge = fct.rouge_evaluations(\" \".join(summary), paragraph_target)\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        # summary_conc = \"\\n\".join(summary)\n",
    "        # save_txt(summary_conc, f\"summaries/{method}/\", \"summary_train_0.txt\") #save train_0 summary\n",
    "        \n",
    "        results.append({'Method': file_type+'_'+method,\n",
    "                        'rouge1': bb25_rouge[0],\n",
    "                        'rouge2': bb25_rouge[1],\n",
    "                        'rougeL': bb25_rouge[2],\n",
    "                        'Execution Time': execution_time\n",
    "                        })\n",
    "        \n",
    "    return results, summary\n",
    "\n",
    "results = []\n",
    "\n",
    "# Évaluation des modèles pour le fichier JSON\n",
    "r, _ = evaluate_models(document_json, paragraph_target_json, \"JSON\")\n",
    "results += r\n",
    "\n",
    "# Évaluation des modèles pour le fichier TXT\n",
    "r, txt_summary = evaluate_models(document_txt, paragraph_target_json, \"TXT\")  # Utilise le même paragraphe cible\n",
    "results += r\n",
    "r, cleaned_txt_summary = evaluate_models(clean_document_txt, paragraph_target_json, \"Cleaned TXT\")  # Utilise le même paragraphe cible\n",
    "results += r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"the court rejected respondent 's remaining challenges to his conviction , and the state supreme court declined review .\", \"the path to the jury 's guilty verdicts on the murder and attempted-murder charges was not an easy one .\", 'you then apply the law to those facts as i state it to you , and you must accept and follow the law .', 'the law is right there , and i think elements of the law was [ sic ] given to you in those instructions .', '* * *', '< a > 10 < /a > per curiam', 'accordingly , the comments made and not made by the court to the jury did not coerce a particular verdict or deny packer any constitutional rights .', \"that court dismissed the petition , but granted a certificate of appealability on the question whether the state trial judge violated respondent 's fourteenth amendment rights by coercing the jury into rendering a verdict on the attempted-murder and second-degree murder counts .\", '< a > 5 < /a > room , and , in the presence of the attorneys and the defendant , read the note aloud .', 'the judge thanked her and returned her to the jury room .']\n",
      "['* * *', 'per curiam', 'you then apply the law to those facts as i state it to you , and you must accept and follow the law .', 'the law is right there , and i think elements of the law was [ sic ] given to you in those instructions .', 'jenkins and gypsumco .', '291 f. 3d , at 578579 , and n. 10 .', 'accordingly , the comments madeand not made by the court to the jury did not coerce a particularverdict or deny packer any constitutional rights .', \"that court dismissed the petition , but granted a certificate of appealability on the question whether the state trial judge violated respondent 's fourteenth amendment rights by coercing the jury into rendering a verdict on the attempted-murder and second-degree murder counts .\", 'ii', '']\n"
     ]
    }
   ],
   "source": [
    "print(txt_summary)\n",
    "print(cleaned_txt_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a08c2_row0_col1, #T_a08c2_row0_col3, #T_a08c2_row1_col2, #T_a08c2_row2_col4 {\n",
       "  background-color: rgba(200, 50, 50, 1.0);\n",
       "}\n",
       "#T_a08c2_row0_col2, #T_a08c2_row1_col1, #T_a08c2_row1_col3, #T_a08c2_row1_col4 {\n",
       "  background-color: rgba(200, 50, 50, 0.6666666666666667);\n",
       "}\n",
       "#T_a08c2_row2_col1, #T_a08c2_row2_col2, #T_a08c2_row2_col3, #T_a08c2_row3_col4 {\n",
       "  background-color: rgba(200, 50, 50, 0.33333333333333337);\n",
       "}\n",
       "#T_a08c2_row4_col1, #T_a08c2_row6_col4, #T_a08c2_row7_col2, #T_a08c2_row10_col3 {\n",
       "  background-color: rgba(50, 200, 50, 0.6666666666666667);\n",
       "}\n",
       "#T_a08c2_row4_col2, #T_a08c2_row4_col3, #T_a08c2_row8_col4, #T_a08c2_row10_col1 {\n",
       "  background-color: rgba(50, 200, 50, 0.33333333333333337);\n",
       "}\n",
       "#T_a08c2_row7_col1, #T_a08c2_row7_col3, #T_a08c2_row10_col2, #T_a08c2_row10_col4 {\n",
       "  background-color: rgba(50, 200, 50, 1.0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a08c2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a08c2_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_a08c2_level0_col1\" class=\"col_heading level0 col1\" >rouge1</th>\n",
       "      <th id=\"T_a08c2_level0_col2\" class=\"col_heading level0 col2\" >rouge2</th>\n",
       "      <th id=\"T_a08c2_level0_col3\" class=\"col_heading level0 col3\" >rougeL</th>\n",
       "      <th id=\"T_a08c2_level0_col4\" class=\"col_heading level0 col4\" >Execution Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a08c2_row0_col0\" class=\"data row0 col0\" >JSON_nltk</td>\n",
       "      <td id=\"T_a08c2_row0_col1\" class=\"data row0 col1\" >0.085658</td>\n",
       "      <td id=\"T_a08c2_row0_col2\" class=\"data row0 col2\" >0.023118</td>\n",
       "      <td id=\"T_a08c2_row0_col3\" class=\"data row0 col3\" >0.032685</td>\n",
       "      <td id=\"T_a08c2_row0_col4\" class=\"data row0 col4\" >13.875355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a08c2_row1_col0\" class=\"data row1 col0\" >JSON_spacy</td>\n",
       "      <td id=\"T_a08c2_row1_col1\" class=\"data row1 col1\" >0.117647</td>\n",
       "      <td id=\"T_a08c2_row1_col2\" class=\"data row1 col2\" >0.017751</td>\n",
       "      <td id=\"T_a08c2_row1_col3\" class=\"data row1 col3\" >0.082353</td>\n",
       "      <td id=\"T_a08c2_row1_col4\" class=\"data row1 col4\" >62.144917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a08c2_row2_col0\" class=\"data row2 col0\" >JSON_pySBD</td>\n",
       "      <td id=\"T_a08c2_row2_col1\" class=\"data row2 col1\" >0.141643</td>\n",
       "      <td id=\"T_a08c2_row2_col2\" class=\"data row2 col2\" >0.028490</td>\n",
       "      <td id=\"T_a08c2_row2_col3\" class=\"data row2 col3\" >0.090652</td>\n",
       "      <td id=\"T_a08c2_row2_col4\" class=\"data row2 col4\" >63.073558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a08c2_row3_col0\" class=\"data row3 col0\" >JSON_custom_spacy</td>\n",
       "      <td id=\"T_a08c2_row3_col1\" class=\"data row3 col1\" >0.178161</td>\n",
       "      <td id=\"T_a08c2_row3_col2\" class=\"data row3 col2\" >0.034682</td>\n",
       "      <td id=\"T_a08c2_row3_col3\" class=\"data row3 col3\" >0.103448</td>\n",
       "      <td id=\"T_a08c2_row3_col4\" class=\"data row3 col4\" >60.064394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a08c2_row4_col0\" class=\"data row4 col0\" >TXT_nltk</td>\n",
       "      <td id=\"T_a08c2_row4_col1\" class=\"data row4 col1\" >0.466102</td>\n",
       "      <td id=\"T_a08c2_row4_col2\" class=\"data row4 col2\" >0.165957</td>\n",
       "      <td id=\"T_a08c2_row4_col3\" class=\"data row4 col3\" >0.194915</td>\n",
       "      <td id=\"T_a08c2_row4_col4\" class=\"data row4 col4\" >8.458565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a08c2_row5_col0\" class=\"data row5 col0\" >TXT_spacy</td>\n",
       "      <td id=\"T_a08c2_row5_col1\" class=\"data row5 col1\" >0.371287</td>\n",
       "      <td id=\"T_a08c2_row5_col2\" class=\"data row5 col2\" >0.124378</td>\n",
       "      <td id=\"T_a08c2_row5_col3\" class=\"data row5 col3\" >0.188119</td>\n",
       "      <td id=\"T_a08c2_row5_col4\" class=\"data row5 col4\" >9.822311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a08c2_row6_col0\" class=\"data row6 col0\" >TXT_pySBD</td>\n",
       "      <td id=\"T_a08c2_row6_col1\" class=\"data row6 col1\" >0.368182</td>\n",
       "      <td id=\"T_a08c2_row6_col2\" class=\"data row6 col2\" >0.114155</td>\n",
       "      <td id=\"T_a08c2_row6_col3\" class=\"data row6 col3\" >0.181818</td>\n",
       "      <td id=\"T_a08c2_row6_col4\" class=\"data row6 col4\" >8.138017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a08c2_row7_col0\" class=\"data row7 col0\" >TXT_custom_spacy</td>\n",
       "      <td id=\"T_a08c2_row7_col1\" class=\"data row7 col1\" >0.478070</td>\n",
       "      <td id=\"T_a08c2_row7_col2\" class=\"data row7 col2\" >0.167401</td>\n",
       "      <td id=\"T_a08c2_row7_col3\" class=\"data row7 col3\" >0.206140</td>\n",
       "      <td id=\"T_a08c2_row7_col4\" class=\"data row7 col4\" >9.750938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a08c2_row8_col0\" class=\"data row8 col0\" >Cleaned TXT_nltk</td>\n",
       "      <td id=\"T_a08c2_row8_col1\" class=\"data row8 col1\" >0.229692</td>\n",
       "      <td id=\"T_a08c2_row8_col2\" class=\"data row8 col2\" >0.090141</td>\n",
       "      <td id=\"T_a08c2_row8_col3\" class=\"data row8 col3\" >0.128852</td>\n",
       "      <td id=\"T_a08c2_row8_col4\" class=\"data row8 col4\" >8.167267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a08c2_row9_col0\" class=\"data row9 col0\" >Cleaned TXT_spacy</td>\n",
       "      <td id=\"T_a08c2_row9_col1\" class=\"data row9 col1\" >0.400966</td>\n",
       "      <td id=\"T_a08c2_row9_col2\" class=\"data row9 col2\" >0.126214</td>\n",
       "      <td id=\"T_a08c2_row9_col3\" class=\"data row9 col3\" >0.188406</td>\n",
       "      <td id=\"T_a08c2_row9_col4\" class=\"data row9 col4\" >9.426583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_a08c2_row10_col0\" class=\"data row10 col0\" >Cleaned TXT_pySBD</td>\n",
       "      <td id=\"T_a08c2_row10_col1\" class=\"data row10 col1\" >0.463158</td>\n",
       "      <td id=\"T_a08c2_row10_col2\" class=\"data row10 col2\" >0.169133</td>\n",
       "      <td id=\"T_a08c2_row10_col3\" class=\"data row10 col3\" >0.202105</td>\n",
       "      <td id=\"T_a08c2_row10_col4\" class=\"data row10 col4\" >7.786820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a08c2_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_a08c2_row11_col0\" class=\"data row11 col0\" >Cleaned TXT_custom_spacy</td>\n",
       "      <td id=\"T_a08c2_row11_col1\" class=\"data row11 col1\" >0.357683</td>\n",
       "      <td id=\"T_a08c2_row11_col2\" class=\"data row11 col2\" >0.121519</td>\n",
       "      <td id=\"T_a08c2_row11_col3\" class=\"data row11 col3\" >0.171285</td>\n",
       "      <td id=\"T_a08c2_row11_col4\" class=\"data row11 col4\" >9.439366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13d393c89d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "def highlight_min_max(df):\n",
    "    styles = pd.DataFrame('', index=df.index, columns=df.columns)\n",
    "\n",
    "    # Appliquer le style pour les colonnes 'Precision', 'Recall', 'F1-Score'\n",
    "    for col in ['rouge1', 'rouge2', 'rougeL']:\n",
    "        # Top 3 maximums et minimums\n",
    "        top_3_max = df[col].nlargest(3)\n",
    "        top_3_min = df[col].nsmallest(3)\n",
    "\n",
    "        # Appliquer le dégradé vert pour les max\n",
    "        for i in df.index:\n",
    "            if df[col].iloc[i] in top_3_max.values:\n",
    "                rank = top_3_max.rank(ascending=False)[top_3_max == df[col].iloc[i]].values[0]\n",
    "                alpha = 1 - (rank - 1) / 3\n",
    "                styles.loc[i, col]= f'background-color: rgba(50, 200, 50, {alpha});'\n",
    "\n",
    "        # Appliquer le dégradé rouge pour les min\n",
    "        for i in df.index:\n",
    "            if df[col].iloc[i] in top_3_min.values:\n",
    "                rank = top_3_min.rank()[top_3_min == df[col].iloc[i]].values[0]\n",
    "                alpha = 1 - (rank - 1) / 3  \n",
    "                styles.loc[i, col]= f'background-color: rgba(200, 50, 50, {alpha});'\n",
    "\n",
    "    # Pour la colonne 'Execution Time', inverser les couleurs (max en rouge, min en vert)\n",
    "    col = 'Execution Time'\n",
    "    top_3_max = df[col].nlargest(3)\n",
    "    top_3_min = df[col].nsmallest(3)\n",
    "\n",
    "    # Appliquer le dégradé rouge pour les max\n",
    "    for i in df.index:\n",
    "        if df[col].iloc[i] in top_3_max.values:\n",
    "            rank = top_3_max.rank(ascending=False)[top_3_max == df[col].iloc[i]].values[0]\n",
    "            alpha = 1 - (rank - 1) / 3 \n",
    "            styles.loc[i, col]= f'background-color: rgba(200, 50, 50, {alpha});'\n",
    "\n",
    "    # Appliquer le dégradé vert pour les min\n",
    "    for i in df.index:\n",
    "        if df[col].iloc[i] in top_3_min.values:\n",
    "            rank = top_3_min.rank()[top_3_min == df[col].iloc[i]].values[0]\n",
    "            alpha = 1 - (rank - 1) / 3 \n",
    "            styles.loc[i, col]= f'background-color: rgba(50, 200, 50, {alpha});'\n",
    "            \n",
    "    return styles\n",
    "\n",
    "styled_df = df.style.apply(highlight_min_max, axis=None)\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try pySBD on 20 cleaned documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>Execution Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txt</td>\n",
       "      <td>0.293587</td>\n",
       "      <td>0.077637</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>6.186914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleaned txt</td>\n",
       "      <td>0.266624</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>0.138787</td>\n",
       "      <td>5.867955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Text    rouge1    rouge2    rougeL  Execution Time\n",
       "0          txt  0.293587  0.077637  0.152772        6.186914\n",
       "1  cleaned txt  0.266624  0.069339  0.138787        5.867955"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_result = []\n",
    "cleaned_txt_result = []\n",
    "\n",
    "methods = ['pySBD']\n",
    "\n",
    "for i in range(0, 20):\n",
    "\n",
    "    document_json = train_json[i][\"raw_source\"]\n",
    "    paragraph_target_json = (\n",
    "        train_json[i]['raw_target']['facts_of_the_case'] +\n",
    "        train_json[i]['raw_target']['question'] +\n",
    "        train_json[i]['raw_target']['conclusion']\n",
    "    )\n",
    "\n",
    "    path_txt = 'data_txt_save/train_'+ str(i) + '.txt'\n",
    "    document_txt = fct.open_file(path_txt, \"txt\")\n",
    "    clean_path_txt = 'clean_data_txt_save/train_'+ str(i) + '.txt'\n",
    "    clean_document_txt = fct.open_file(clean_path_txt, \"txt\")\n",
    "    \n",
    "    r, _ = evaluate_models(document_txt, paragraph_target_json, \"TXT\")  \n",
    "    txt_result += r\n",
    "    r, _ = evaluate_models(clean_document_txt, paragraph_target_json, \"Cleaned TXT\")  \n",
    "    cleaned_txt_result += r\n",
    "    \n",
    "txt_df = pd.DataFrame(txt_result)  \n",
    "cleaned_txt_df = pd.DataFrame(cleaned_txt_result)\n",
    "\n",
    "mean_txt = txt_df[['rouge1', 'rouge2', 'rougeL', 'Execution Time']].mean()\n",
    "mean_cleaned_txt = cleaned_txt_df[['rouge1', 'rouge2', 'rougeL', 'Execution Time']].mean()\n",
    "\n",
    "\n",
    "final_df = pd.DataFrame({\n",
    "    'Text': ['txt', 'cleaned txt'],\n",
    "    'rouge1': [mean_txt['rouge1'], mean_cleaned_txt['rouge1']],\n",
    "    'rouge2': [mean_txt['rouge2'], mean_cleaned_txt['rouge2']],\n",
    "    'rougeL': [mean_txt['rougeL'], mean_cleaned_txt['rougeL']],\n",
    "    'Execution Time': [mean_txt['Execution Time'], mean_cleaned_txt['Execution Time']]\n",
    "})\n",
    "\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
