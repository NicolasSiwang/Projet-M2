{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install bm25s\n",
    "# %pip install spacy\n",
    "# %pip install -U 'spacy[cuda12x]'\n",
    "# %pip install rouge_score\n",
    "# %pip install pysbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as fct\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Définition des chemins vers les fichiers JSON d'entraînement et de développement\n",
    "# train_path = 'SCOTUS/train.json'\n",
    "# dev_path = 'SCOTUS/dev.json'\n",
    "\n",
    "# # Ouverture du fichier d'entraînement\n",
    "# train = fct.open_file(train_path, \"json\")\n",
    "\n",
    "# # Récupération du document source du premier élément de l'ensemble d'entraînement\n",
    "# # document = train[0][\"raw_source\"]\n",
    "# document = train\n",
    "\n",
    "# # Récupération des éléments de la cible (faits, question, conclusion)\n",
    "# paragraph_target = (\n",
    "#     train[0]['raw_target']['facts_of_the_case'] +\n",
    "#     train[0]['raw_target']['question'] +\n",
    "#     train[0]['raw_target']['conclusion']\n",
    "# )\n",
    "\n",
    "# train_path = 'data_txt_save/train_0.txt'\n",
    "# train = fct.open_file(train_path, \"txt\")\n",
    "\n",
    "# document = train\n",
    "\n",
    "\n",
    "# # Segmentation des phrases du document source\n",
    "# sentences = fct.sent_segmentation(document, method='custom_spacy')\n",
    "\n",
    "# # Résumé des phrases en utilisant le modèle BERT\n",
    "# summary = fct.bb25LegalSum(sentences, \"bert-base-uncased\", 5)\n",
    "\n",
    "# # Évaluation de la qualité du résumé à l'aide de la métrique ROUGE\n",
    "# bb25_rouge = fct.rouge_evaluations(\" \".join(summary), paragraph_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb25_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des chemins vers les fichiers JSON d'entraînement et de développement\n",
    "train_path_json = 'SCOTUS/train.json'\n",
    "dev_path_json = 'SCOTUS/dev.json'\n",
    "\n",
    "# Ouverture du fichier d'entraînement JSON\n",
    "train_json = fct.open_file(train_path_json, \"json\")\n",
    "\n",
    "text_number = 0\n",
    "\n",
    "# Récupération du document source et des éléments de la cible (faits, question, conclusion)\n",
    "document_json = train_json[text_number][\"raw_source\"]\n",
    "paragraph_target_json = (\n",
    "    train_json[text_number]['raw_target']['facts_of_the_case'] +\n",
    "    train_json[text_number]['raw_target']['question'] +\n",
    "    train_json[text_number]['raw_target']['conclusion']\n",
    ")\n",
    "\n",
    "# Définir le chemin du fichier texte à traiter\n",
    "text_path = f'data_txt_save/text/train_{text_number}.txt'\n",
    "\n",
    "# Ouverture du fichier d'entraînement TXT\n",
    "document_txt = fct.open_file(text_path, \"txt\")\n",
    "\n",
    "# Liste des méthodes de segmentation et des modèles à tester\n",
    "methods = ['nltk', 'spacy', 'pySBD', 'custom_spacy']  # Méthodes de segmentation à tester\n",
    "\n",
    "model = \"bert-base-uncased\"  # Modèle de résumé à utiliser\n",
    "\n",
    "def save_txt(text, folder_name, file_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(text)\n",
    "\n",
    "# Fonction pour évaluer les modèles\n",
    "def evaluate_models(document, paragraph_target, file_type):\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    for method in methods:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Segmentation des phrases du document source\n",
    "        sentences = fct.sent_segmentation(document, method=method)\n",
    "        \n",
    "        # Résumé des phrases\n",
    "        query = fct.select_query(document)\n",
    "        summary = fct.bb25LegalSum(sentences, model, query)\n",
    "        \n",
    "        # Évaluation de la qualité du résumé à l'aide de la métrique ROUGE\n",
    "        bb25_rouge = fct.rouge_evaluations(\" \".join(summary), paragraph_target)\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "                \n",
    "        result = bb25_rouge.set_index(' ').T\n",
    "        result.insert(0, 'Method', file_type+'_'+method)\n",
    "        result['Execution time'] = execution_time\n",
    "        \n",
    "        summary_conc = \"\\n\".join(summary)\n",
    "        save_txt(summary_conc, f\"summaries/{method}/\", f\"summary_train_{text_number}.txt\") #save train_n summary\n",
    "        \n",
    "        results = pd.concat([results, result], ignore_index=True)\n",
    "        \n",
    "    return results, summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sur 1 texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "# Évaluation des modèles pour le fichier JSON\n",
    "r, _ = evaluate_models(document_json, paragraph_target_json, \"JSON\")\n",
    "results = pd.concat([results, r], ignore_index=True)\n",
    "\n",
    "result, summary = evaluate_models(document_txt, paragraph_target_json, \"TXT\")  # Utilise le même paragraphe cible\n",
    "results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def highlight_min_max(df):\n",
    "    styles = pd.DataFrame('', index=df.index, columns=df.columns)\n",
    "\n",
    "    # Appliquer le style pour les colonnes 'Precision', 'Recall', 'F1-Score'\n",
    "    for col in ['rouge1', 'rouge2', 'rougeL']:\n",
    "        # Top 3 maximums et minimums\n",
    "        top_3_max = df[col].nlargest(3)\n",
    "        top_3_min = df[col].nsmallest(3)\n",
    "\n",
    "        # Appliquer le dégradé rouge pour les min\n",
    "        for i in df.index:\n",
    "            if df[col].iloc[i] in top_3_min.values:\n",
    "                rank = top_3_min.rank()[top_3_min == df[col].iloc[i]].values[0]\n",
    "                alpha = 1 - (rank - 1) / 3  \n",
    "                styles.loc[i, col]= f'background-color: rgba(200, 50, 50, {alpha});'\n",
    "\n",
    "        # Appliquer le dégradé vert pour les max\n",
    "        for i in df.index:\n",
    "            if df[col].iloc[i] in top_3_max.values:\n",
    "                rank = top_3_max.rank(ascending=False)[top_3_max == df[col].iloc[i]].values[0]\n",
    "                alpha = 1 - (rank - 1) / 3\n",
    "                styles.loc[i, col]= f'background-color: rgba(50, 200, 50, {alpha});'\n",
    "\n",
    "    # Pour la colonne 'Execution time', inverser les couleurs (max en rouge, min en vert)\n",
    "    col = 'Execution time'\n",
    "    top_3_max = df[col].nlargest(3)\n",
    "    top_3_min = df[col].nsmallest(3)\n",
    "\n",
    "    # Appliquer le dégradé vert pour les min\n",
    "    for i in df.index:\n",
    "        if df[col].iloc[i] in top_3_min.values:\n",
    "            rank = top_3_min.rank()[top_3_min == df[col].iloc[i]].values[0]\n",
    "            alpha = 1 - (rank - 1) / 3 \n",
    "            styles.loc[i, col]= f'background-color: rgba(50, 200, 50, {alpha});'\n",
    "\n",
    "    # Appliquer le dégradé rouge pour les max\n",
    "    for i in df.index:\n",
    "        if df[col].iloc[i] in top_3_max.values:\n",
    "            rank = top_3_max.rank(ascending=False)[top_3_max == df[col].iloc[i]].values[0]\n",
    "            alpha = 1 - (rank - 1) / 3 \n",
    "            styles.loc[i, col]= f'background-color: rgba(200, 50, 50, {alpha});'\n",
    "            \n",
    "    return styles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choix segmenteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9df60_row0_col1, #T_9df60_row2_col2, #T_9df60_row2_col3, #T_9df60_row2_col4 {\n",
       "  background-color: rgba(200, 50, 50, 0.6666666666666667);\n",
       "}\n",
       "#T_9df60_row0_col3, #T_9df60_row1_col4, #T_9df60_row2_col1, #T_9df60_row3_col2 {\n",
       "  background-color: rgba(200, 50, 50, 1.0);\n",
       "}\n",
       "#T_9df60_row1_col2, #T_9df60_row3_col1, #T_9df60_row3_col3, #T_9df60_row3_col4 {\n",
       "  background-color: rgba(200, 50, 50, 0.33333333333333337);\n",
       "}\n",
       "#T_9df60_row4_col1, #T_9df60_row4_col2, #T_9df60_row4_col3, #T_9df60_row6_col4 {\n",
       "  background-color: rgba(50, 200, 50, 1.0);\n",
       "}\n",
       "#T_9df60_row4_col4, #T_9df60_row5_col3, #T_9df60_row6_col2, #T_9df60_row7_col1 {\n",
       "  background-color: rgba(50, 200, 50, 0.6666666666666667);\n",
       "}\n",
       "#T_9df60_row6_col1, #T_9df60_row7_col2, #T_9df60_row7_col3, #T_9df60_row7_col4 {\n",
       "  background-color: rgba(50, 200, 50, 0.33333333333333337);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9df60\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" > </th>\n",
       "      <th id=\"T_9df60_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_9df60_level0_col1\" class=\"col_heading level0 col1\" >rouge1</th>\n",
       "      <th id=\"T_9df60_level0_col2\" class=\"col_heading level0 col2\" >rouge2</th>\n",
       "      <th id=\"T_9df60_level0_col3\" class=\"col_heading level0 col3\" >rougeL</th>\n",
       "      <th id=\"T_9df60_level0_col4\" class=\"col_heading level0 col4\" >Execution time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9df60_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9df60_row0_col0\" class=\"data row0 col0\" >JSON_nltk</td>\n",
       "      <td id=\"T_9df60_row0_col1\" class=\"data row0 col1\" >0.229056</td>\n",
       "      <td id=\"T_9df60_row0_col2\" class=\"data row0 col2\" >0.107219</td>\n",
       "      <td id=\"T_9df60_row0_col3\" class=\"data row0 col3\" >0.111347</td>\n",
       "      <td id=\"T_9df60_row0_col4\" class=\"data row0 col4\" >46.867264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9df60_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9df60_row1_col0\" class=\"data row1 col0\" >JSON_spacy</td>\n",
       "      <td id=\"T_9df60_row1_col1\" class=\"data row1 col1\" >0.265130</td>\n",
       "      <td id=\"T_9df60_row1_col2\" class=\"data row1 col2\" >0.081159</td>\n",
       "      <td id=\"T_9df60_row1_col3\" class=\"data row1 col3\" >0.161383</td>\n",
       "      <td id=\"T_9df60_row1_col4\" class=\"data row1 col4\" >180.383457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9df60_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9df60_row2_col0\" class=\"data row2 col0\" >JSON_pySBD</td>\n",
       "      <td id=\"T_9df60_row2_col1\" class=\"data row2 col1\" >0.174194</td>\n",
       "      <td id=\"T_9df60_row2_col2\" class=\"data row2 col2\" >0.077922</td>\n",
       "      <td id=\"T_9df60_row2_col3\" class=\"data row2 col3\" >0.116129</td>\n",
       "      <td id=\"T_9df60_row2_col4\" class=\"data row2 col4\" >179.452980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9df60_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9df60_row3_col0\" class=\"data row3 col0\" >JSON_custom_spacy</td>\n",
       "      <td id=\"T_9df60_row3_col1\" class=\"data row3 col1\" >0.254545</td>\n",
       "      <td id=\"T_9df60_row3_col2\" class=\"data row3 col2\" >0.057441</td>\n",
       "      <td id=\"T_9df60_row3_col3\" class=\"data row3 col3\" >0.145455</td>\n",
       "      <td id=\"T_9df60_row3_col4\" class=\"data row3 col4\" >157.501788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9df60_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9df60_row4_col0\" class=\"data row4 col0\" >TXT_nltk</td>\n",
       "      <td id=\"T_9df60_row4_col1\" class=\"data row4 col1\" >0.537477</td>\n",
       "      <td id=\"T_9df60_row4_col2\" class=\"data row4 col2\" >0.234862</td>\n",
       "      <td id=\"T_9df60_row4_col3\" class=\"data row4 col3\" >0.266910</td>\n",
       "      <td id=\"T_9df60_row4_col4\" class=\"data row4 col4\" >14.211957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9df60_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_9df60_row5_col0\" class=\"data row5 col0\" >TXT_spacy</td>\n",
       "      <td id=\"T_9df60_row5_col1\" class=\"data row5 col1\" >0.404762</td>\n",
       "      <td id=\"T_9df60_row5_col2\" class=\"data row5 col2\" >0.172249</td>\n",
       "      <td id=\"T_9df60_row5_col3\" class=\"data row5 col3\" >0.257143</td>\n",
       "      <td id=\"T_9df60_row5_col4\" class=\"data row5 col4\" >16.704587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9df60_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_9df60_row6_col0\" class=\"data row6 col0\" >TXT_pySBD</td>\n",
       "      <td id=\"T_9df60_row6_col1\" class=\"data row6 col1\" >0.500000</td>\n",
       "      <td id=\"T_9df60_row6_col2\" class=\"data row6 col2\" >0.216028</td>\n",
       "      <td id=\"T_9df60_row6_col3\" class=\"data row6 col3\" >0.215278</td>\n",
       "      <td id=\"T_9df60_row6_col4\" class=\"data row6 col4\" >13.212178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9df60_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_9df60_row7_col0\" class=\"data row7 col0\" >TXT_custom_spacy</td>\n",
       "      <td id=\"T_9df60_row7_col1\" class=\"data row7 col1\" >0.503049</td>\n",
       "      <td id=\"T_9df60_row7_col2\" class=\"data row7 col2\" >0.195719</td>\n",
       "      <td id=\"T_9df60_row7_col3\" class=\"data row7 col3\" >0.246951</td>\n",
       "      <td id=\"T_9df60_row7_col4\" class=\"data row7 col4\" >16.505785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25b913ef370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "styled_df = df.style.apply(highlight_min_max, axis=None)\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try pySBD on 100 cleaned documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:00:38<00:00, 36.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means :\n",
      " \n",
      "rouge1             0.397978\n",
      "rouge2             0.158284\n",
      "rougeL             0.216640\n",
      "Execution time    36.347295\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "methods = ['pySBD']\n",
    "\n",
    "for i in tqdm(range(0, 100)):\n",
    "\n",
    "    document_json = train_json[i][\"raw_source\"]\n",
    "    paragraph_target_json = (\n",
    "        train_json[i]['raw_target']['facts_of_the_case'] +\n",
    "        train_json[i]['raw_target']['question'] +\n",
    "        train_json[i]['raw_target']['conclusion']\n",
    "    )\n",
    "\n",
    "    text_path = f'data_txt_save/text/train_{i}.txt'\n",
    "    document_txt = fct.open_file(text_path, \"txt\")\n",
    "    \n",
    "    r, _ = evaluate_models(document_txt, paragraph_target_json, \"TXT\")  \n",
    "        \n",
    "    results = pd.concat([results, r], ignore_index=True)\n",
    "    \n",
    "means = results[['rouge1', 'rouge2', 'rougeL', 'Execution time']].mean()\n",
    "\n",
    "print(\"Means :\")\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def highlight_min_max(df):\n",
    "    styles = pd.DataFrame('', index=df.index, columns=df.columns)\n",
    "\n",
    "    # Appliquer le style pour les colonnes 'Precision', 'Recall', 'F1-Score'\n",
    "    for col in ['rouge1', 'rouge2', 'rougeL']:\n",
    "        # Top 3 maximums et minimums\n",
    "        top_3_max = df[col].nlargest(3)\n",
    "        top_3_min = df[col].nsmallest(3)\n",
    "\n",
    "        # Appliquer le dégradé rouge pour les min\n",
    "        for i in df.index:\n",
    "            if df[col].iloc[i] in top_3_min.values:\n",
    "                rank = top_3_min.rank()[top_3_min == df[col].iloc[i]].values[0]\n",
    "                alpha = 1 - (rank - 1) / 3  \n",
    "                styles.loc[i, col]= f'background-color: rgba(200, 50, 50, {alpha});'\n",
    "\n",
    "        # Appliquer le dégradé vert pour les max\n",
    "        for i in df.index:\n",
    "            if df[col].iloc[i] in top_3_max.values:\n",
    "                rank = top_3_max.rank(ascending=False)[top_3_max == df[col].iloc[i]].values[0]\n",
    "                alpha = 1 - (rank - 1) / 3\n",
    "                styles.loc[i, col]= f'background-color: rgba(50, 200, 50, {alpha});'\n",
    "\n",
    "    # Pour la colonne 'Execution time', inverser les couleurs (max en rouge, min en vert)\n",
    "    col = 'Execution time'\n",
    "    top_3_max = df[col].nlargest(3)\n",
    "    top_3_min = df[col].nsmallest(3)\n",
    "\n",
    "    # Appliquer le dégradé vert pour les min\n",
    "    for i in df.index:\n",
    "        if df[col].iloc[i] in top_3_min.values:\n",
    "            rank = top_3_min.rank()[top_3_min == df[col].iloc[i]].values[0]\n",
    "            alpha = 1 - (rank - 1) / 3 \n",
    "            styles.loc[i, col]= f'background-color: rgba(50, 200, 50, {alpha});'\n",
    "\n",
    "    # Appliquer le dégradé rouge pour les max\n",
    "    for i in df.index:\n",
    "        if df[col].iloc[i] in top_3_max.values:\n",
    "            rank = top_3_max.rank(ascending=False)[top_3_max == df[col].iloc[i]].values[0]\n",
    "            alpha = 1 - (rank - 1) / 3 \n",
    "            styles.loc[i, col]= f'background-color: rgba(200, 50, 50, {alpha});'\n",
    "    return styles\n",
    "\n",
    "styled_df = results.style.apply(highlight_min_max, axis=None)\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We hold that, as a general rule, when a litigant’s recovery constitutes income, the litigant’s income includes the portion of the recovery paid to the attorney as a contingent fee. ', 'Six Courts of Appeals have held the entire litigation recovery, including the portion paid to an attorney as a contingent fee, is income to the plaintiff. ', 'In the other case under review,  Banaitis  v.  Commissioner , 340 F. 3d 1074 (2003), the Court of Appeals for the Ninth Circuit held that the portion of the recovery paid to the attorney as a contingent fee is excluded from the plaintiff’s gross income if state law gives the plaintiff’s attorney a special property interest in the fee, but not otherwise. ', 'Sometimes, as when the plaintiff seeks only injunctive relief, or when the statute caps plaintiffs’ recoveries, or when for other reasons damages are substantially less than attorney’s fees, court-awarded attorney’s fees can exceed a plaintiff’s monetary recovery. ', 'The Commissioner maintains that a contingent-fee agreement should be viewed as an anticipatory assignment to the attorney of a portion of the client’s income from any litigation recovery. ']\n"
     ]
    }
   ],
   "source": [
    "i = 59\n",
    "document_json = train_json[i][\"raw_source\"]\n",
    "paragraph_target_json = (\n",
    "    train_json[i]['raw_target']['facts_of_the_case'] +\n",
    "    train_json[i]['raw_target']['question'] +\n",
    "    train_json[i]['raw_target']['conclusion']\n",
    ")\n",
    "\n",
    "text_path = f'data_txt_save/text/train_{i}.txt'\n",
    "document_txt = fct.open_file(text_path, \"txt\")\n",
    "\n",
    "methods = ['pySBD']\n",
    "\n",
    "r, summary = evaluate_models(document_txt, paragraph_target_json, \"TXT\")  \n",
    "    \n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
