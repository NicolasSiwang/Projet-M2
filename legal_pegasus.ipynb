{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fb6E1QcSXuBX",
        "outputId": "f2f8fed2-12bd-42de-a36a-4493fb6a414c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (2.0.3)\n",
            "Requirement already satisfied: transformers in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (4.32.1)\n",
            "Requirement already satisfied: torch in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (2.4.1+cu124)\n",
            "Requirement already satisfied: nltk in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (3.7.3)\n",
            "Requirement already satisfied: pysbd in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.3.4)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (1.3.0)\n",
            "Requirement already satisfied: rank-bm25 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.2.2)\n",
            "Requirement already satisfied: rouge-score in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (1.24.3)\n",
            "Requirement already satisfied: json5 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.9.6)\n",
            "Requirement already satisfied: rouge in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: bert_score in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: click in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
            "Requirement already satisfied: joblib in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
            "Requirement already satisfied: setuptools in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: absl-py in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from rouge-score) (2.1.0)\n",
            "Requirement already satisfied: six>=1.14.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from bert_score) (3.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (10.0.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (3.0.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas transformers torch nltk spacy pysbd scikit-learn rank-bm25 rouge-score numpy json5 rouge bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5riGD9OI6A5p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "import torch\n",
        "import os\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import spacy\n",
        "import pysbd\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from rank_bm25 import BM25Okapi\n",
        "from nltk.tokenize import word_tokenize\n",
        "from rouge_score import rouge_scorer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "from rouge import Rouge\n",
        "import concurrent.futures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "094z4mn98jur"
      },
      "outputs": [],
      "source": [
        "train_path = 'dataset_legal-pegasus/dataset/UK-Abs/train-data'\n",
        "test_path = 'dataset_legal-pegasus/dataset/UK-Abs/test-data'\n",
        "\n",
        "train_path_txt = train_path + '/judgement'\n",
        "train_path_summary = train_path + '/summary'\n",
        "test_path_txt = test_path + '/judgement'\n",
        "test_path_summary = test_path + '/summary'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "VMMCFMuZ8yKO",
        "outputId": "3c22ff68-20f5-42dc-db09-e15297cc0b1c"
      },
      "outputs": [],
      "source": [
        "# Parcourir les fichiers dans le dossier de train et de test\n",
        "train_files = os.listdir(train_path_txt)\n",
        "test_files = os.listdir(test_path_txt)\n",
        "\n",
        "# Charger le modèle Legal-Pegasus et le tokenizer\n",
        "model_name = \"nsi319/legal-pegasus\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sgUvJ8Gf82Gv"
      },
      "outputs": [],
      "source": [
        "def open_file(file_path, type):\n",
        "\n",
        "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
        "        if (type == \"json\"):\n",
        "            return json.load(f)\n",
        "        elif (type == \"txt\"):\n",
        "            return f.read()\n",
        "\n",
        "def sent_segmentation(document, method='nltk'):\n",
        "    \"\"\"Segmentation of the document as sentences using the specified method.\n",
        "\n",
        "    Args:\n",
        "        document (str): The document to segment.\n",
        "        method (str): The method to use for segmentation ('nltk', 'spacy', 'custom_spacy' or 'pySBD').\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of tokenized sentences.\n",
        "    \"\"\"\n",
        "    if method == 'nltk':\n",
        "        return sent_tokenize(document)\n",
        "    elif method == 'spacy':\n",
        "        nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
        "        nlp.add_pipe(\"sentencizer\")\n",
        "        split_doc = split(document)\n",
        "        sentences = []\n",
        "        for chunk in split_doc:\n",
        "            chunk = re.sub(r'\\\"', '', chunk)    # remove double quote because error\n",
        "            doc = nlp(chunk)\n",
        "            for sent in doc.sents:\n",
        "                sentences.append(sent.text)\n",
        "        return sentences\n",
        "    elif method == 'custom_spacy':\n",
        "        nlp = csp.custom_spacy_model()\n",
        "        split_doc = split(document)\n",
        "        sentences = []\n",
        "        for chunk in split_doc:\n",
        "            chunk = re.sub(r'\\\"', '', chunk)    # remove double quote because error\n",
        "            doc = nlp(chunk)\n",
        "            for sent in doc.sents:\n",
        "                sentences.append(sent.text)\n",
        "        return sentences\n",
        "    elif method == 'pySBD':\n",
        "        seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
        "        return seg.segment(document)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported tokenization method. Choose 'nltk', 'spacy', or 'custom_spacy'.\")\n",
        "\n",
        "def summarize(text, model_name=\"legal-pegasus\", min_length=150, max_length=250):\n",
        "    \"\"\"Return a summary\"\"\"\n",
        "\n",
        "    if (model_name == \"legal-pegasus\"):\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"nsi319/legal-pegasus\")\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(\"nsi319/legal-pegasus\")\n",
        "        input_tokenized = tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
        "\n",
        "        summary_ids = model.generate(input_tokenized,\n",
        "                                    num_beams=9,\n",
        "                                    no_repeat_ngram_size=3,\n",
        "                                    length_penalty=2.0,\n",
        "                                    min_length=min_length,\n",
        "                                    max_length=max_length,\n",
        "                                    early_stopping=True)\n",
        "\n",
        "        return [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n",
        "    else:\n",
        "        return \"Model not available\"\n",
        "\n",
        "def bb25LegalSum(sentences, model_name=\"bert-base-uncased\", n_clusters = 5):\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertModel.from_pretrained(model_name)\n",
        "    sentence_embeddings = get_sentence_embeddings(sentences, tokenizer, model)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "    kmeans.fit(sentence_embeddings)\n",
        "\n",
        "    # Étiquettes des clusters\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    cluster = {}\n",
        "    for i in range(n_clusters):\n",
        "        #print(f\"\\nCluster {i+1}:\")\n",
        "        cluster[i] = []\n",
        "        for j, sentence in enumerate(sentences):\n",
        "            if labels[j] == i:\n",
        "                #print(f\"- {sentence}\")\n",
        "                cluster[i].append(sentence)\n",
        "\n",
        "    silhouette_avg = silhouette_score(sentence_embeddings, labels)\n",
        "    #print(f\"\\nSilhouette Score: {silhouette_avg}\")\n",
        "\n",
        "    tokenized_clusters = {}\n",
        "\n",
        "    # Tokenisation des documents pour chaque cluster\n",
        "    for i, sentences in cluster.items():\n",
        "        tokenized_clusters[i] = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "    # Initialiser un modèle BM25 pour chaque cluster\n",
        "    bm25_models = {}\n",
        "    for i, tokenized_docs in tokenized_clusters.items():\n",
        "        bm25_models[i] = BM25Okapi(tokenized_docs)\n",
        "\n",
        "    query = \"law and legal rights\"\n",
        "    tokenized_query = word_tokenize(query.lower())\n",
        "\n",
        "    for cluster_id, bm25 in bm25_models.items():\n",
        "        # Calcul des scores pour la requête dans chaque cluster\n",
        "        scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "\n",
        "    best_sentences = []\n",
        "\n",
        "    for cluster_id, bm25 in bm25_models.items():\n",
        "            # Récupérer les phrases les plus pertinentes pour la requête dans ce cluster\n",
        "            top_docs = bm25.get_top_n(tokenized_query, tokenized_clusters[cluster_id], n=2)\n",
        "\n",
        "            # Extraire les phrases pertinentes et les ajouter à la liste\n",
        "            for doc in top_docs:\n",
        "                sentence = ' '.join(doc)  # Convertir le tokenized doc en phrase\n",
        "                best_sentences.append(sentence)\n",
        "\n",
        "    return best_sentences\n",
        "\n",
        "\n",
        "\n",
        "def get_sentence_embeddings(sentences, tokenizer, model):\n",
        "    \"\"\"Obtenir les embeddings de phrases avec BERT\n",
        "    Args:\n",
        "        sentences (List[str]): Liste des phrases à encoder\n",
        "        tokenizer (transformers.PreTrainedTokenizer): Tokenizer BERT\n",
        "        model (transformers.PreTrainedModel): Modèle BERT\n",
        "    Returns:\n",
        "        np.array: Tableau des embeddings de phrases\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy())  # Moyenne des embeddings\n",
        "    return np.array(embeddings)\n",
        "\n",
        "def split(text, max_length=3530):\n",
        "    split_text = text.split('\\n')\n",
        "    result = []\n",
        "\n",
        "    for chunk in split_text:\n",
        "        while len(chunk) > max_length:\n",
        "            sub_chunk = chunk[:max_length]\n",
        "            last_period_position = sub_chunk.rfind('.')\n",
        "\n",
        "            if last_period_position == -1:\n",
        "                last_period_position = max_length\n",
        "\n",
        "            if chunk[:last_period_position+1].strip():\n",
        "                result.append(chunk[:last_period_position+1].strip())\n",
        "            chunk = chunk[last_period_position+1:].strip()\n",
        "\n",
        "        if chunk and chunk.strip():\n",
        "            result.append(chunk.strip())\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def evaluation(text, ref):\n",
        "    rouges = rouge_evaluations(text, ref)\n",
        "\n",
        "def rouge_evaluations(text, ref):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(text, ref)\n",
        "\n",
        "    return rouge_to_df(scores)\n",
        "\n",
        "def rouge_to_df(scores):\n",
        "\n",
        "    data = {\n",
        "        'Metric': [],\n",
        "        'Precision': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': []\n",
        "    }\n",
        "\n",
        "    for metric, score in scores.items():\n",
        "        data['Metric'].append(metric)\n",
        "        data['Precision'].append(score.precision)\n",
        "        data['Recall'].append(score.recall)\n",
        "        data['F1-Score'].append(score.fmeasure)\n",
        "\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "soUv6wwH9MEb"
      },
      "outputs": [],
      "source": [
        "# Fonction pour diviser le document en segments\n",
        "def chunk_text(text, chunk_size=1024):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=chunk_size, truncation=True, padding=True)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "\n",
        "    for i, word in enumerate(text.split()):\n",
        "        if current_length + len(word) <= chunk_size:\n",
        "            current_chunk.append(word)\n",
        "            current_length += len(word) + 1\n",
        "        else:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = [word]\n",
        "            current_length = len(word) + 1\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GKZauLAh9QQi"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# reference_summary = open_file(train_path_txt + '/' + train_files[0], 'txt')\n",
        "# print(len(reference_summary))\n",
        "\n",
        "# # Générer le résumé\n",
        "# chunks = chunk_text(reference_summary)\n",
        "# print(len(chunks))\n",
        "\n",
        "# generated_summary = [summarize(chunk, \"legal-pegasus\", max_length=1000) for chunk in chunks[:2]]\n",
        "# # generated_summary = summarize(chunks[0], \"legal-pegasus\", max_length=1000)\n",
        "\n",
        "# print(\"flag 2\")\n",
        "\n",
        "# # print(\"Résumé de référence : \", reference_summary)\n",
        "# # print(\"Résumé généré : \", generated_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SmDe5aM3gk2n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de tokens dans le résumé de référence: 279249\n",
            "Nombre de chunks: 274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Nicolas\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=map_location)\n"
          ]
        }
      ],
      "source": [
        "# Fonction pour traiter un chunk\n",
        "def summarize_chunk(chunk):\n",
        "    return summarize(chunk, \"legal-pegasus\", max_length=1000)\n",
        "\n",
        "# Charger le fichier de référence\n",
        "reference_summary = open_file(train_path_txt + '/' + train_files[0], 'txt')\n",
        "print(f\"Nombre de tokens dans le résumé de référence: {len(reference_summary)}\")\n",
        "\n",
        "# Diviser le texte en chunks\n",
        "chunks = chunk_text(reference_summary)\n",
        "print(f\"Nombre de chunks: {len(chunks)}\")\n",
        "\n",
        "# Utiliser ThreadPoolExecutor pour le traitement parallèle\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    generated_summary = list(executor.map(summarize_chunk, chunks))\n",
        "\n",
        "print(\"Flag 2 - Traitement par lots terminé\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hQqI0wpG9TwN"
      },
      "outputs": [],
      "source": [
        "# Fonction pour calculer les scores ROUGE\n",
        "def compute_rouge_scores(reference_summary, generated_summary):\n",
        "    print(\"flag 3\")\n",
        "    rouge = Rouge()\n",
        "\n",
        "    # Calcul des scores ROUGE-1, ROUGE-2 et ROUGE-L\n",
        "    scores = rouge.get_scores(generated_summary, reference_summary)\n",
        "    print(\"flag3-1\")\n",
        "\n",
        "\n",
        "    # S'assurer que des scores ont été calculés avant de procéder\n",
        "    if len(scores) == 0:\n",
        "        return {\"error\": \"No scores could be computed. Check your input summaries.\"}\n",
        "\n",
        "    # Calcul de la moyenne des scores\n",
        "    avg_scores = {\n",
        "        'rouge-1': {\n",
        "            'precision': sum([score['rouge-1']['p'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'recall': sum([score['rouge-1']['r'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'f1-score': sum([score['rouge-1']['f'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "        },\n",
        "        'rouge-2': {\n",
        "            'precision': sum([score['rouge-2']['p'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'recall': sum([score['rouge-2']['r'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'f1-score': sum([score['rouge-2']['f'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "        },\n",
        "        'rouge-l': {\n",
        "            'precision': sum([score['rouge-l']['p'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'recall': sum([score['rouge-l']['r'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'f1-score': sum([score['rouge-l']['f'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return avg_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gXPAoa-2b-PO"
      },
      "outputs": [],
      "source": [
        "generated_summary = ' '.join(generated_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jhz_1Vbt-HOh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flag 3\n",
            "flag3-1\n",
            "flag 4\n",
            "ROUGE-1:  {'precision': 0.9477124183006536, 'recall': 0.027756508422664625, 'f1-score': 0.053933419569847665}\n",
            "ROUGE-2:  {'precision': 0.8764478764478765, 'recall': 0.01004291465734637, 'f1-score': 0.019858279891465463}\n",
            "ROUGE-L:  {'precision': 0.9477124183006536, 'recall': 0.027756508422664625, 'f1-score': 0.053933419569847665}\n"
          ]
        }
      ],
      "source": [
        "rouge_scores = compute_rouge_scores(reference_summary, generated_summary)\n",
        "\n",
        "print(\"flag 4\")\n",
        "\n",
        "# Vérification et affichage des scores\n",
        "if \"error\" in rouge_scores:\n",
        "    print(rouge_scores[\"error\"])\n",
        "else:\n",
        "    print(\"ROUGE-1: \", rouge_scores['rouge-1'])\n",
        "    print(\"ROUGE-2: \", rouge_scores['rouge-2'])\n",
        "    print(\"ROUGE-L: \", rouge_scores['rouge-l'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4X3Jg9KVBCjD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1685\n",
            "279249\n"
          ]
        }
      ],
      "source": [
        "print(len(generated_summary))\n",
        "print(len(reference_summary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aiuuibQI__uf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9cd22757c684df2abc1e76bdfb23de4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "463b07506e384698b665fa80ecc88f3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 1.74 seconds, 0.58 sentences/sec\n",
            "Précision (P): 0.9357\n",
            "Rappel (R): 0.8927\n",
            "F1-Score: 0.9137\n"
          ]
        }
      ],
      "source": [
        "from bert_score import score\n",
        "\n",
        "# Calculer le score BERTScore\n",
        "P, R, F1 = score([generated_summary], [reference_summary], lang=\"en\", verbose=True)\n",
        "\n",
        "# Afficher les scores de Précision, Rappel et F1\n",
        "print(f\"Précision (P): {P.mean().item():.4f}\")\n",
        "print(f\"Rappel (R): {R.mean().item():.4f}\")\n",
        "print(f\"F1-Score: {F1.mean().item():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
