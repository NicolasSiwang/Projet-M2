{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fb6E1QcSXuBX",
        "outputId": "0c6fe20d-368f-45d6-8d53-2da908a7367a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (2.0.3)\n",
            "Requirement already satisfied: transformers in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (4.32.1)\n",
            "Requirement already satisfied: torch in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (2.4.1+cu124)\n",
            "Requirement already satisfied: nltk in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (3.7.3)\n",
            "Requirement already satisfied: pysbd in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.3.4)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (1.3.0)\n",
            "Requirement already satisfied: rank-bm25 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.2.2)\n",
            "Requirement already satisfied: rouge-score in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (1.24.3)\n",
            "Requirement already satisfied: json5 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.9.6)\n",
            "Requirement already satisfied: rouge in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: bert_score in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (0.3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: click in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
            "Requirement already satisfied: joblib in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
            "Requirement already satisfied: setuptools in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
            "Requirement already satisfied: absl-py in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from rouge-score) (2.1.0)\n",
            "Requirement already satisfied: six>=1.14.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from bert_score) (3.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (10.0.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from matplotlib->bert_score) (3.0.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nicolas\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas transformers torch nltk spacy pysbd scikit-learn rank-bm25 rouge-score numpy json5 rouge bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5riGD9OI6A5p"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Nicolas\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "c:\\Users\\Nicolas\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "c:\\Users\\Nicolas\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "import torch\n",
        "import os\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import spacy\n",
        "import pysbd\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from rank_bm25 import BM25Okapi\n",
        "from nltk.tokenize import word_tokenize\n",
        "from rouge_score import rouge_scorer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "from rouge import Rouge\n",
        "import concurrent.futures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "094z4mn98jur"
      },
      "outputs": [],
      "source": [
        "train_path = 'dataset_legal-pegasus/dataset/UK-Abs/train-data'\n",
        "test_path = 'dataset_legal-pegasus/dataset/UK-Abs/test-data'\n",
        "\n",
        "train_path_txt = train_path + '/judgement'\n",
        "train_path_summary = train_path + '/summary'\n",
        "test_path_txt = test_path + '/judgement'\n",
        "test_path_summary = test_path + '/summary'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMMCFMuZ8yKO",
        "outputId": "21622fab-21de-4bd4-dcd2-f1c04f38d1a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le modèle est sur : cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Nicolas\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=map_location)\n"
          ]
        }
      ],
      "source": [
        "# Parcourir les fichiers dans le dossier de train et de test\n",
        "train_files = os.listdir(train_path_txt)\n",
        "test_files = os.listdir(test_path_txt)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Vérifier si le modèle est sur GPU\n",
        "print(f\"Le modèle est sur : {device}\")\n",
        "\n",
        "\n",
        "# Charger le modèle Legal-Pegasus et le tokenizer\n",
        "model_name = \"nsi319/legal-pegasus\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sgUvJ8Gf82Gv"
      },
      "outputs": [],
      "source": [
        "def open_file(file_path, type):\n",
        "\n",
        "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
        "        if (type == \"json\"):\n",
        "            return json.load(f)\n",
        "        elif (type == \"txt\"):\n",
        "            return f.read()\n",
        "\n",
        "def split_text(text, tokenizer, max_length=1024):\n",
        "    \"\"\"Split the text into chunks that fit the model's input size\"\"\"\n",
        "    input_ids = tokenizer.encode(text, return_tensors='pt', truncation=False)\n",
        "    chunks = []\n",
        "    for i in range(0, len(input_ids[0]), max_length):\n",
        "        chunk = input_ids[:, i:i+max_length]\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "def summarize_large_text(text, model_name=\"legal-pegasus\", min_length=150, max_length=250):\n",
        "    \"\"\"Summarize large texts by splitting them into chunks and summarizing each chunk\"\"\"\n",
        "\n",
        "    if model_name == \"legal-pegasus\":\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"nsi319/legal-pegasus\")\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(\"nsi319/legal-pegasus\")\n",
        "\n",
        "        chunks = split_text(text, tokenizer)\n",
        "        print(len(chunks))\n",
        "        summaries = []\n",
        "\n",
        "        for chunk in chunks[:2]:\n",
        "            summary_ids = model.generate(chunk,\n",
        "                                         num_beams=9,\n",
        "                                         no_repeat_ngram_size=3,\n",
        "                                         length_penalty=2.0,\n",
        "                                         min_length=min_length,\n",
        "                                         max_length=max_length,\n",
        "                                         early_stopping=True)\n",
        "            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "            summaries.append(summary)\n",
        "\n",
        "        # Combine all chunk summaries into one\n",
        "        return ' '.join(summaries)\n",
        "\n",
        "    else:\n",
        "        return \"Model not available\"\n",
        "\n",
        "def evaluation(text, ref):\n",
        "    rouges = rouge_evaluations(text, ref)\n",
        "\n",
        "def rouge_evaluations(text, ref):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(text, ref)\n",
        "\n",
        "    return rouge_to_df(scores)\n",
        "\n",
        "def rouge_to_df(scores):\n",
        "\n",
        "    data = {\n",
        "        'Metric': [],\n",
        "        'Precision': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': []\n",
        "    }\n",
        "\n",
        "    for metric, score in scores.items():\n",
        "        data['Metric'].append(metric)\n",
        "        data['Precision'].append(score.precision)\n",
        "        data['Recall'].append(score.recall)\n",
        "        data['F1-Score'].append(score.fmeasure)\n",
        "\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "teCjLWdVfFx0",
        "outputId": "5f1b7030-130f-4750-e8e2-ba707a896f03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (54024 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53\n"
          ]
        }
      ],
      "source": [
        "reference_judgement = open_file(train_path_txt + '/' + train_files[0], 'txt')\n",
        "\n",
        "generated_summary = summarize_large_text(reference_judgement, model_name=\"legal-pegasus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP2bX3VSfcWA",
        "outputId": "55512d85-187d-48b4-cecf-97713e96a22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On 13 December 2006 the appellant Mohammed al Ghabra, referred to in these proceedings as G, was informed that a direction had been made against him by HM Treasury under article 4 of the Terrorism (United Nations Measures) Order 2006 (SI 2006/2657). He was told that the Treasury had reasonable grounds for suspecting that he was, or might be, a person who facilitated the commission of acts of terrorism. The effect of the direction was to prohibit him from dealing with his funds and economic resources and to prevent anyone notified of the freeze from making funds, economic resources or financial services available to him or for his benefit. On 2 August 2007 the appellants Mohammed Jabar Ahmed, Mohammed Azmir Khan and Michael Marteen (formerly known as Mohammed Tunveer Ahmed) received letters in almost identical terms telling them that they had been designated under the TO by the Treasury. In September 2005 Hani El Sayed Sabaei Youssef (or Hani al Sebai) was also told that his name had been added to the Consolidated List by the 1267 Committee. As a result he too was deemed to be a designated person under the AQO. The Order provides for the freezing, without limit of time, of the funds, Economic resources and The case brings us face to face with the kind of issue that led to Lord Atkins famously powerful protest against a construction of a Defence Regulation which had the effect of giving an absolute and uncontrolled power of imprisonment to the minister. Even in the face of the threat of international terrorism, the safety of the people is not the supreme law. We must be just as careful to guard against unrestrained encroachments on personal liberty. The case raises fundamental questions about the relationship between Parliament and the executive and about judicial control over the power of the executive. The consequences of the Orders that were made in this case are so drastic and so oppressive that we must be as alert to see that the coercive action that the Treasury have taken really is within the powers that the 1946 Act has given them. The Charter of the United Nations was signed in San Francisco on 26 June 1945 as the Second World War was coming to an end. It was designed to save succeeding generations from the scourge of war, to reaffirm faith in fundamental human rights and to establish conditions under which justice and respect for the obligations arising from treaties and other sources of international law can be maintained. Member states bound themselves to maintain international peace and security, to take collective measures for the prevention and removal of threats to the\n"
          ]
        }
      ],
      "source": [
        "print(generated_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hQqI0wpG9TwN"
      },
      "outputs": [],
      "source": [
        "# Fonction pour calculer les scores ROUGE\n",
        "def compute_rouge_scores(reference_summary, generated_summary):\n",
        "    print(\"flag 3\")\n",
        "    rouge = Rouge()\n",
        "\n",
        "    # Calcul des scores ROUGE-1, ROUGE-2 et ROUGE-L\n",
        "    scores = rouge.get_scores(generated_summary, reference_summary)\n",
        "    print(\"flag3-1\")\n",
        "\n",
        "\n",
        "    # S'assurer que des scores ont été calculés avant de procéder\n",
        "    if len(scores) == 0:\n",
        "        return {\"error\": \"No scores could be computed. Check your input summaries.\"}\n",
        "\n",
        "    # Calcul de la moyenne des scores\n",
        "    avg_scores = {\n",
        "        'rouge-1': {\n",
        "            'precision': sum([score['rouge-1']['p'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'recall': sum([score['rouge-1']['r'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'f1-score': sum([score['rouge-1']['f'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "        },\n",
        "        'rouge-2': {\n",
        "            'precision': sum([score['rouge-2']['p'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'recall': sum([score['rouge-2']['r'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'f1-score': sum([score['rouge-2']['f'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "        },\n",
        "        'rouge-l': {\n",
        "            'precision': sum([score['rouge-l']['p'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'recall': sum([score['rouge-l']['r'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "            'f1-score': sum([score['rouge-l']['f'] for score in scores]) / len(scores) if len(scores) > 0 else 0,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return avg_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhz_1Vbt-HOh",
        "outputId": "4276fbc5-8d8d-425e-9206-bf79302faf2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flag 3\n",
            "flag3-1\n",
            "flag 4\n",
            "ROUGE-1:  {'precision': 0.3607843137254902, 'recall': 0.20175438596491227, 'f1-score': 0.25879043140522356}\n",
            "ROUGE-2:  {'precision': 0.10869565217391304, 'recall': 0.048283261802575105, 'f1-score': 0.06686478028733008}\n",
            "ROUGE-L:  {'precision': 0.3176470588235294, 'recall': 0.17763157894736842, 'f1-score': 0.22784809666542052}\n"
          ]
        }
      ],
      "source": [
        "reference_summary = open_file(train_path_summary + '/' + \"uksc-2009-0018.txt\", 'txt')\n",
        "\n",
        "rouge_scores = compute_rouge_scores(reference_summary, generated_summary)\n",
        "\n",
        "print(\"flag 4\")\n",
        "\n",
        "# Vérification et affichage des scores\n",
        "if \"error\" in rouge_scores:\n",
        "    print(rouge_scores[\"error\"])\n",
        "else:\n",
        "    print(\"ROUGE-1: \", rouge_scores['rouge-1'])\n",
        "    print(\"ROUGE-2: \", rouge_scores['rouge-2'])\n",
        "    print(\"ROUGE-L: \", rouge_scores['rouge-l'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X3Jg9KVBCjD",
        "outputId": "b78aac5b-f854-4499-d6cc-8d5f7de79852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2629\n",
            "6922\n"
          ]
        }
      ],
      "source": [
        "print(len(generated_summary))\n",
        "print(len(reference_summary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 436,
          "referenced_widgets": [
            "4b2285a4a73c4d45b5d373859d6df5c5",
            "e21c98ce2cae433e9e1297b8726150e3"
          ]
        },
        "id": "aiuuibQI__uf",
        "outputId": "2c70df36-39ab-4d84-f348-ea1966216d46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d923775838043169a424e4c25d84228",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72256d43b69344b9961cdd3e95261fb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 8.34 seconds, 0.12 sentences/sec\n",
            "Précision (P): 0.8100\n",
            "Rappel (R): 0.8229\n",
            "F1-Score: 0.8164\n"
          ]
        }
      ],
      "source": [
        "from bert_score import score\n",
        "\n",
        "# Calculer le score BERTScore\n",
        "P, R, F1 = score([generated_summary], [reference_summary], lang=\"en\", verbose=True)\n",
        "\n",
        "# Afficher les scores de Précision, Rappel et F1\n",
        "print(f\"Précision (P): {P.mean().item():.4f}\")\n",
        "print(f\"Rappel (R): {R.mean().item():.4f}\")\n",
        "print(f\"F1-Score: {F1.mean().item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
