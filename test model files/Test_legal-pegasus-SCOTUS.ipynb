{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33892,"status":"ok","timestamp":1732263024710,"user":{"displayName":"Nicolas Stucky","userId":"07416246260327876992"},"user_tz":-60},"id":"esm55ACb8vqe","outputId":"e66e49db-cf59-4ebf-dc62-55269dbca6b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6266,"status":"ok","timestamp":1732263030972,"user":{"displayName":"Nicolas Stucky","userId":"07416246260327876992"},"user_tz":-60},"id":"3qoYA39QYcEy","outputId":"864ffbcc-05ba-4ba7-8597-d41e4153d50b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.6)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=c922863668a89f59d7cf409711dbfbe1fd83c286b6dfb42168dbbf61dd7b3b71\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n"]}],"source":["%pip install rouge-score"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1732263030973,"user":{"displayName":"Nicolas Stucky","userId":"07416246260327876992"},"user_tz":-60},"id":"yqh1rO2q8zgU"},"outputs":[],"source":["model_path = \"/content/drive/MyDrive/legal-pegasus-model-Scopus\"\n","\n","test_path = '/content/drive/MyDrive/SCOTU_data_txt_save'\n","\n","test_path_txt = test_path + '/text_dev'\n","test_path_summary = test_path + '/summary_dev'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":98964,"status":"ok","timestamp":1732263129931,"user":{"displayName":"Nicolas Stucky","userId":"07416246260327876992"},"user_tz":-60},"id":"9JUCGYqa9dRb"},"outputs":[],"source":["from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n","\n","# Charger le modèle et le tokenizer\n","model = PegasusForConditionalGeneration.from_pretrained(model_path)\n","tokenizer = PegasusTokenizer.from_pretrained(model_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":19319,"status":"ok","timestamp":1732263149242,"user":{"displayName":"Nicolas Stucky","userId":"07416246260327876992"},"user_tz":-60},"id":"XPmAL7nM9dyQ"},"outputs":[],"source":["import os\n","\n","def load_test_data(txt_path, summary_path):\n","    \"\"\"Charge les fichiers texte et résumés pour le jeu de test.\"\"\"\n","    texts = []\n","    summaries = []\n","\n","    for file_name in os.listdir(txt_path):\n","        with open(os.path.join(txt_path, file_name), 'r', encoding='utf-8') as f:\n","            texts.append(f.read())\n","\n","    for file_name in os.listdir(summary_path):\n","        with open(os.path.join(summary_path, file_name), 'r', encoding='utf-8') as f:\n","            summaries.append(f.read())\n","\n","    return texts, summaries\n","\n","# Charger les données\n","test_path_txt = test_path + '/text_dev'\n","test_path_summary = test_path + '/summary_dev'\n","\n","texts, summaries = load_test_data(test_path_txt, test_path_summary)\n","\n","# Vérifier un exemple\n","# print(\"Texte original :\", texts[0])\n","# print(\"Résumé attendu :\", summaries[0])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1732263149243,"user":{"displayName":"Nicolas Stucky","userId":"07416246260327876992"},"user_tz":-60},"id":"aPljwyAuYBw-","outputId":"8b5ea373-e31a-4711-b2ae-a3935ce5c2b8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PegasusForConditionalGeneration(\n","  (model): PegasusModel(\n","    (shared): Embedding(96103, 1024, padding_idx=0)\n","    (encoder): PegasusEncoder(\n","      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","      (layers): ModuleList(\n","        (0-15): 16 x PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): ReLU()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): PegasusDecoder(\n","      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","      (layers): ModuleList(\n","        (0-15): 16 x PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_fn): ReLU()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",")"]},"metadata":{},"execution_count":6}],"source":["import torch\n","\n","def generate_summary(model, tokenizer, text, max_input_length=1024, max_output_length=256):\n","    \"\"\"Génère un résumé pour un texte donné.\"\"\"\n","    inputs = tokenizer(\n","        text, max_length=max_input_length, truncation=True, return_tensors=\"pt\", padding=\"longest\"\n","    ).input_ids\n","    inputs = inputs.to(model.device)  # S'assurer que les données sont sur le bon appareil\n","\n","    # Génération\n","    output_ids = model.generate(\n","        inputs, max_length=max_output_length, num_beams=5, length_penalty=2.0, early_stopping=True\n","    )\n","    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","\n","# Générer un résumé pour un exemple\n","model.eval()\n","model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zMJ3f_VWYNMx"},"outputs":[],"source":["from rouge_score import rouge_scorer\n","from tqdm import tqdm\n","\n","def evaluate_model(model, tokenizer, texts, references, max_input_length=1024, max_output_length=256):\n","    \"\"\"Évalue les performances du modèle sur les données de test.\"\"\"\n","    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","    scores = []\n","\n","    for text, reference in zip(texts, references):\n","        generated_summary = generate_summary(model, tokenizer, text, max_input_length, max_output_length)\n","        score = scorer.score(reference, generated_summary)\n","        scores.append(score)\n","\n","    # Moyennes des scores\n","    avg_scores = {\n","        'rouge1': sum(s['rouge1'].fmeasure for s in scores) / len(scores),\n","        'rouge2': sum(s['rouge2'].fmeasure for s in scores) / len(scores),\n","        'rougeL': sum(s['rougeL'].fmeasure for s in scores) / len(scores),\n","    }\n","    return avg_scores\n","\n","# Évaluer le modèle\n","results = evaluate_model(model, tokenizer, texts, summaries)\n","print(\"Scores ROUGE :\", results)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7tdt6TuYWDe"},"outputs":[],"source":["import pandas as pd\n","\n","df_results = pd.DataFrame({\"Text\": texts, \"Reference\": summaries, \"Generated\": [generate_summary(model, tokenizer, t) for t in texts]})\n","df_results.to_csv(\"/content/drive/MyDrive/results_legal-pegasus-SCOTUS.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_UhmZyQXZD8Z"},"outputs":[],"source":["# example_generated_summary = generate_summary(model, tokenizer, texts[0])\n","# print(\"Résumé généré :\", example_generated_summary)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPLKxELxHkoyYdYISgKyX/R"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}